{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "LB3eLu4qgikf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using the StableBaselines3 library for reinforcement learning\n",
    "\n",
    "In this notebook we test an implementation of the proximal policy optimization (PPO)\n",
    "PPO is described in detail in https://arxiv.org/abs/1707.06347. It is a variant of Trust Region Policy Optimization (TRPO) described (in this paper )[https://arxiv.org/abs/1502.05477]. The PPO algorithm works in two phases. In one phase, a large number of rollouts are performed (in parallel). The rollouts are then aggregated on the driver and a surrogate optimization objective is defined based on those rollouts. We then use SGD to find the policy that maximizes that objective with a penalty term for diverging too much from the current policy.\n",
    "\n",
    "![ppo](https://raw.githubusercontent.com/ucbrise/risecamp/risecamp2018/ray/tutorial/rllib_exercises/ppo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing the required libraries and our OpenAI-Gym compatible environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p_dir = \"/hdd/junxuanl/ML-proj-BPP/src\"\n",
    "\n",
    "if p_dir not in sys.path:\n",
    "    sys.path.append(p_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZ0M4QIzuqCV",
    "outputId": "eac9dda6-7b79-440a-be99-a71bf5839034",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import warnings\n",
    "\n",
    "import gymnasium as gym\n",
    "from PIL import Image\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "from src.utils import boxes_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hmtegq1thfbj",
    "outputId": "5d01bd0e-a91e-4dfa-90d6-90e45911869c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_env(\n",
    "        container_size,\n",
    "        num_boxes,\n",
    "        num_visible_boxes=1,\n",
    "        seed=0,\n",
    "        render_mode=None,\n",
    "        random_boxes=False,\n",
    "        only_terminal_reward=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "    container_size: size of the container\n",
    "    num_boxes: number of boxes to be packed\n",
    "    num_visible_boxes: number of boxes visible to the agent\n",
    "    seed: seed for RNG\n",
    "    render_mode: render mode for the environment\n",
    "    random_boxes: whether to use random boxes or not\n",
    "    only_terminal_reward: whether to use only terminal reward or not\n",
    "    \"\"\"\n",
    "    env = gym.make(\n",
    "        \"PackingEnv-v0\",\n",
    "        container_size=container_size,\n",
    "        box_sizes=boxes_generator(container_size),\n",
    "        num_visible_boxes=num_visible_boxes,\n",
    "        render_mode=render_mode,\n",
    "        random_boxes=random_boxes,\n",
    "        only_terminal_reward=only_terminal_reward,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we set up the environment for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6G0GQanQiRqw",
    "outputId": "83de09c6-46ba-402e-9763-a3efee3c11d9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "from gym import make\n",
    "box_size,t=boxes_generator([100, 100, 100])\n",
    "env = make(\n",
    "        \"PackingEnv-v0\",\n",
    "        container_size=[100, 100, 100],\n",
    "        box_sizes=box_size,\n",
    "        num_visible_boxes=1,\n",
    "        random_boxes=True,\n",
    "    )\n",
    "box_size,t=boxes_generator([100, 100, 100])\n",
    "env_test = make(\n",
    "        \"PackingEnv-v0\",\n",
    "        container_size=[100, 100, 100],\n",
    "        box_sizes=box_size,\n",
    "        num_visible_boxes=1,\n",
    "        random_boxes=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We train the agent with the default multi-input policy that uses an MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KMCuiduujfKh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:2 device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "begin training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m MaskablePPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/binpacking/lib/python3.8/site-packages/sb3_contrib/ppo_mask/ppo_mask.py:521\u001b[0m, in \u001b[0;36mMaskablePPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, use_masking, progress_bar)\u001b[0m\n\u001b[1;32m    518\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 521\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_masking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/binpacking/lib/python3.8/site-packages/sb3_contrib/ppo_mask/ppo_mask.py:296\u001b[0m, in \u001b[0;36mMaskablePPO.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps, use_masking)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# This is the only change related to invalid action masking\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_masking:\n\u001b[0;32m--> 296\u001b[0m         action_masks \u001b[38;5;241m=\u001b[39m \u001b[43mget_action_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy(obs_tensor, action_masks\u001b[38;5;241m=\u001b[39maction_masks)\n\u001b[1;32m    300\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/binpacking/lib/python3.8/site-packages/sb3_contrib/common/maskable/utils.py:17\u001b[0m, in \u001b[0;36mget_action_masks\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03mChecks whether gym env exposes a method returning invalid action masks\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m:param env: the Gym environment to get masks from\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m:return: A numpy array of the masks\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env, VecEnv):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXPECTED_METHOD_NAME\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(env, EXPECTED_METHOD_NAME)()\n",
      "File \u001b[0;32m~/miniconda3/envs/binpacking/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:126\u001b[0m, in \u001b[0;36mDummyVecEnv.env_method\u001b[0;34m(self, method_name, indices, *method_args, **method_kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m target_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_envs(indices)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mgetattr\u001b[39m(env_i, method_name)(\u001b[38;5;241m*\u001b[39mmethod_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmethod_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m env_i \u001b[38;5;129;01min\u001b[39;00m target_envs]\n",
      "File \u001b[0;32m~/miniconda3/envs/binpacking/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:126\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m target_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_envs(indices)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m env_i \u001b[38;5;129;01min\u001b[39;00m target_envs]\n",
      "File \u001b[0;32m/hdd/junxuanl/ML-proj-BPP/src/packing_env.py:432\u001b[0m, in \u001b[0;36mPackingEnv.action_masks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m act_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    424\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_visible_boxes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint8,\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpacked_visible_boxes)):\n\u001b[0;32m--> 432\u001b[0m     acm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpacked_visible_boxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_area\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     act_mask[index] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    436\u001b[0m         acm, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m    437\u001b[0m     )\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m act_mask\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m/hdd/junxuanl/ML-proj-BPP/src/packing_kernel.py:475\u001b[0m, in \u001b[0;36mContainer.action_mask\u001b[0;34m(self, box, check_area)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    474\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 475\u001b[0m                 \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_valid_box_placement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_area\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m                 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    479\u001b[0m             ):\n\u001b[1;32m    480\u001b[0m                 action_mask[i,j,k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action_mask\n",
      "File \u001b[0;32m/hdd/junxuanl/ML-proj-BPP/src/packing_kernel.py:357\u001b[0m, in \u001b[0;36mContainer.check_valid_box_placement\u001b[0;34m(self, box, new_pos, rotation, check_area)\u001b[0m\n\u001b[1;32m    353\u001b[0m box\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(box\u001b[38;5;241m.\u001b[39msize)[get_rotation_array(rotation)]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# print(box.size)\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# print(np.asarray(box.size)[get_rotation_array(rotation)])\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Generate the vertices of the bottom face of the box\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_vertices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# bottom vertices of the box\u001b[39;00m\n\u001b[1;32m    359\u001b[0m v0, v1, v2, v3 \u001b[38;5;241m=\u001b[39m v[\u001b[38;5;241m0\u001b[39m, :], v[\u001b[38;5;241m1\u001b[39m, :], v[\u001b[38;5;241m2\u001b[39m, :], v[\u001b[38;5;241m3\u001b[39m, :]\n",
      "File \u001b[0;32m/hdd/junxuanl/ML-proj-BPP/src/utils.py:159\u001b[0m, in \u001b[0;36mgenerate_vertices\u001b[0;34m(cuboid_len_edges, cuboid_position)\u001b[0m\n\u001b[1;32m    156\u001b[0m v0 \u001b[38;5;241m=\u001b[39m cuboid_position\n\u001b[1;32m    158\u001b[0m v1 \u001b[38;5;241m=\u001b[39m v0 \u001b[38;5;241m+\u001b[39m [cuboid_len_edges[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 159\u001b[0m v2 \u001b[38;5;241m=\u001b[39m \u001b[43mv0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuboid_len_edges\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    160\u001b[0m v3 \u001b[38;5;241m=\u001b[39m v0 \u001b[38;5;241m+\u001b[39m [cuboid_len_edges[\u001b[38;5;241m0\u001b[39m], cuboid_len_edges[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m v4 \u001b[38;5;241m=\u001b[39m v0 \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, cuboid_len_edges[\u001b[38;5;241m2\u001b[39m]]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "#把一个模型放到GPU上\n",
    " \n",
    "device = torch.device(\"cuda:2\")\n",
    "\n",
    "\n",
    "model = MaskablePPO(\"MultiInputPolicy\", env, verbose=1,device=device)\n",
    "print(\"begin training\")\n",
    "model.learn(total_timesteps=10000)\n",
    "print(\"done training\")\n",
    "model.save(\"ppo_mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we roll out the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "done packing\n"
     ]
    }
   ],
   "source": [
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "\n",
    "obs = orig_env.reset()\n",
    "done = False\n",
    "figs = []\n",
    "fig = orig_env.render(mode=\"human\")\n",
    "fig_png = fig.to_image(format=\"png\")\n",
    "buf = io.BytesIO(fig_png)\n",
    "img = Image.open(buf)\n",
    "figs.append(img)\n",
    "step = 1\n",
    "while not done:\n",
    "    print(step)\n",
    "    action_masks = get_action_masks(env)\n",
    "    action, _states = model.predict(obs, deterministic=False, action_masks=action_masks)\n",
    "    obs, rewards, done, info = orig_env.step(action)\n",
    "    fig = orig_env.render(mode=\"human\")\n",
    "    fig_png = fig.to_image(format=\"png\")\n",
    "    buf = io.BytesIO(fig_png)\n",
    "    img = Image.open(buf)\n",
    "    figs.append(img)\n",
    "    step += 1\n",
    "print(\"done packing\")\n",
    "orig_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we save the rollout as a gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figs[0].save('../gifs/train_5_boxes.gif', format='GIF',\n",
    "             append_images=figs[1:],\n",
    "             save_all=True,\n",
    "             duration=300, loop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "binpacking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
